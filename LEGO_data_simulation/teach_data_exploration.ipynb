{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-astronomy",
   "metadata": {},
   "source": [
    "# Exploring TEACh Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hired-latitude",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:44.950115Z",
     "start_time": "2023-11-22T12:29:44.945998Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consecutive-lancaster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:45.542710Z",
     "start_time": "2023-11-22T12:29:45.542405Z"
    }
   },
   "outputs": [],
   "source": [
    "from teach.dataset.definitions import Definitions\n",
    "from teach.dataset.dataset import Dataset\n",
    "from teach.dataset.actions import Action_Keyboard, Action_ObjectInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "united-committee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:46.443593Z",
     "start_time": "2023-11-22T12:29:46.440470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Edit data directory if changed when using `teach_download`\n",
    "data_dir = \"/media/PampusData/jpei/teach-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_game_files\t\tedh_instances.tar.gz\t     images_and_states.tar.gz\r\n",
      "all_games.tar.gz\tet_pretrained_models.tar.gz  IMAGESLICENSE\r\n",
      "baseline_models.tar.gz\texperiment_games.tar.gz      tfd_instances.tar.gz\r\n",
      "DATALICENSE\t\tgames\r\n",
      "edh_instances\t\timages\r\n"
     ]
    }
   ],
   "source": [
    "! ls /media/PampusData/jpei/teach-dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:47.679355Z",
     "start_time": "2023-11-22T12:29:47.560518Z"
    }
   },
   "id": "8fb244e147ba6969"
  },
  {
   "cell_type": "markdown",
   "id": "tribal-amsterdam",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-ferry",
   "metadata": {},
   "source": [
    "Instantiate a `Definitions` object to access various definitions, mappings of agent IDs and actions to names, as well as task definitions. \n",
    "The code uses `Driver` when referring to the `Follower` in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-manner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:51.056989Z",
     "start_time": "2023-11-22T12:29:51.019014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent IDs to agents:  OrderedDict([(0, OrderedDict([('agent_name', 'Commander'), ('agent_type', 0)])), (1, OrderedDict([('agent_name', 'Driver'), ('agent_type', 1)]))])\n",
      "Status IDs to names:  OrderedDict([(0, 'Success'), (1, 'Failure')])\n"
     ]
    }
   ],
   "source": [
    "definitions = Definitions(version=\"2.0\")\n",
    "print(\"Agent IDs to agents: \", definitions.map_agents_id2info)\n",
    "print(\"Status IDs to names: \", definitions.map_status_id2name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-finger",
   "metadata": {},
   "source": [
    "Display mappings of action IDs to action names. Note that only a subset of these are used in TEACh data. Note that `definitions.map_tasks_name2info` ends up being more useful when trying to access actions by name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "realistic-feelings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:57.895755Z",
     "start_time": "2023-11-22T12:29:57.857049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action IDs to names:\n",
      "\t  0 : Stop\n",
      "\t  1 : Move to\n",
      "\t  2 : Forward\n",
      "\t  3 : Backward\n",
      "\t  4 : Turn Left\n",
      "\t  5 : Turn Right\n",
      "\t  6 : Look Up\n",
      "\t  7 : Look Down\n",
      "\t  8 : Pan Left\n",
      "\t  9 : Pan Right\n",
      "\t  10 : Move Up\n",
      "\t  11 : Move Down\n",
      "\t  12 : Double Forward\n",
      "\t  13 : Double Backward\n",
      "\t  300 : Navigation\n",
      "\t  200 : Pickup\n",
      "\t  201 : Place\n",
      "\t  202 : Open\n",
      "\t  203 : Close\n",
      "\t  204 : ToggleOn\n",
      "\t  205 : ToggleOff\n",
      "\t  206 : Slice\n",
      "\t  207 : Dirty\n",
      "\t  208 : Clean\n",
      "\t  209 : Fill\n",
      "\t  210 : Empty\n",
      "\t  211 : Pour\n",
      "\t  212 : Break\n",
      "\t  400 : BehindAboveOn\n",
      "\t  401 : BehindAboveOff\n",
      "\t  500 : OpenProgressCheck\n",
      "\t  501 : SelectOid\n",
      "\t  502 : SearchObject\n",
      "\t  100 : Text\n",
      "\t  101 : Speech\n",
      "\t  102 : Beep\n"
     ]
    }
   ],
   "source": [
    "print(\"Action IDs to names:\")\n",
    "for action_id, action in definitions.map_actions_id2info.items():\n",
    "    print(\"\\t \", action_id, \":\", action[\"action_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-protest",
   "metadata": {},
   "source": [
    "Tasks are also most convenient to access by name via `definitions.map_tasks_name2info` but can be accessed via ID using `definitions.map_tasks_id2info`. The values of both of these dictionaries are of type `Task_THOR`.  \n",
    "\n",
    "When a `Definitions` object is instantiated, all tasks defined under `src/teach/meta_data_files/task_definitions` get loaded. The Task Definition Language is explained in Appendix F of the [TEACh paper](https://arxiv.org/pdf/2110.00534.pdf). To create a new task, create a new JSON file under `src/teach/meta_data_files/task_definitions`. Each task needs to have a unique `task_id` and `task_name`. Tasks can be referenced in other tasks by their `task_name`. After creating a new task, test that it can be loaded any any inter-task dependencies can be resolved by instantiating a `Definitions` object.\n",
    "\n",
    "The following code snippet demonstrates how to print a few task details. Note that `#n` (where `n` is a number) indicates a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "effective-yugoslavia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:29:59.336844Z",
     "start_time": "2023-11-22T12:29:59.335184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task details by name:\n",
      "Task name                         Task ID    Num task params      Task component names\n",
      "Candles                             304             0          ['candles', 'bathtub']\n",
      "Breakfast                           301             14         ['coffee', 'toast', 'potatoes', 'apple', 'sandwich', 'salad', 'serving_spot']\n",
      "Salad                               303             3          ['lettuce', 'tomato', 'potato', 'plate']\n",
      "Put All X In One Y                  111             3          ['#0', '#2']\n",
      "N Cooked Slices Of X In Y           107             4          ['#1', '#3']\n",
      "Custom Properties Kitchen Tasks     405             0          ['boiled_potato', 'poached_egg']\n",
      "Boil X                              112             1          ['boiled_#0']\n",
      "Workspace                           305             3          ['writing', 'laptop', 'book', 'gather_spot', 'lights']\n",
      "Toggle X All Y                      116             3          ['#1']\n",
      "Plate Of Toast                      106             0          ['toast', 'plate']\n",
      "Coffee                              102             0          ['coffee']\n",
      "Poach Egg                           113             0          ['poached_egg']\n",
      "Cooked Slice Of X                   105             1          ['#0', 'knife']\n",
      "Put All X On Y                      110             3          ['#0', '#2']\n",
      "Sliced X                            104             1          ['#0', 'knife']\n",
      "Basic Kitchen Tasks                 401             0          ['coffee', 'toast', 'omelette', 'spatula', 'drawer']\n",
      "Clean All X                         115             1          ['#0', 'sink']\n",
      "Clean X                             103             1          ['#0', 'sink']\n",
      "N Slices Of X In Y                  108             4          ['#1', '#3']\n",
      "Omelette                            109             0          ['omelette']\n",
      "Tutorial                            201             0          ['coffee', 'potato']\n",
      "Toast                               101             0          ['toast']\n",
      "Sandwich                            302             2          ['toast', 'lettuce', 'tomato', 'plate']\n",
      "Basic Bathroom Tasks                403             0          ['faucets', 'candles', 'soap', 'counter']\n",
      "Water Plant                         114             0          ['water_plant']\n"
     ]
    }
   ],
   "source": [
    "print(\"Task details by name:\")\n",
    "print(\"Task name\".ljust(33, \" \"), \"Task ID\".ljust(10, \" \"), \"Num task params\".ljust(20, \" \"), \"Task component names\")\n",
    "for task_name, task in definitions.map_tasks_name2info.items():\n",
    "    print(\n",
    "        task_name.ljust(35, \" \"),\n",
    "        str(task.task_id).ljust(15, \" \"),\n",
    "        str(task.task_nparams).ljust(10, \" \"),\n",
    "        str(list(task.components.keys())),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-philadelphia",
   "metadata": {},
   "source": [
    "### Gameplay Sessions\n",
    "Gameplay sessions are stored in `json` files. The `games` subdirectory consists of one subdirectory per split each containing game files of that split. When loaded, these are dictionaries and for many purposes, it is sufficient to analyze the dictionaries. Some examples:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cultural-refund",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:01.121280Z",
     "start_time": "2023-11-22T12:30:01.082419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'task_type', 'comments', 'definitions', 'tasks'])\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)\n",
    "print(game_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-smoke",
   "metadata": {},
   "source": [
    "While the game dictionary contains other keys, the important one is `tasks`. `version`, `task_type` and `comments` are dataset-specific metadata, and `definitions` contains the version of the `Definitions` object used to collect the data. However, all games in the subdirectory `games` have been verified to be replayable and resulting in task success using the current (released) version of the `Definitions` object. `tasks` is always a list of length 1 in this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "colored-metallic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:03.194708Z",
     "start_time": "2023-11-22T12:30:03.192248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task_id', 'task_name', 'task_params', 'task_nparams', 'task_anchor_object', 'desc', 'components', 'relations', 'comments', 'episodes'])\n"
     ]
    }
   ],
   "source": [
    "print(game_dict[\"tasks\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-boating",
   "metadata": {},
   "source": [
    "This is a dictionary that can be converted to a `Task_THOR` object. All keys except `episodes` are associated with the task definition and can be better understood by reading Appendix F of the [TEACh paper](https://arxiv.org/pdf/2110.00534.pdf). For all game files in this dataset `game_dict['tasks'][0]['episodes']` will be a list of length 1 and `game_dict['tasks'][0]['episodes'][0]` contains the actual sequence of actions taken in the episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coated-creature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:04.776413Z",
     "start_time": "2023-11-22T12:30:04.757950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['episode_id', 'world', 'world_type', 'commander_embodied', 'initial_state', 'interactions', 'final_state'])\n"
     ]
    }
   ],
   "source": [
    "print(game_dict[\"tasks\"][0][\"episodes\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-dancing",
   "metadata": {},
   "source": [
    "Episodes are used to store the initial and final simulator state, as well as the sequence of actions taken in a gameplay session. The components of an episode are:\n",
    "* `episode_id` - A unique id\n",
    "* `world_type` - Type of room which is one of `Kitchen`, `Bedroom`, `Bathroom` and `Living room` \n",
    "* `world` - ID of the specific AI2-THOR floor plan used for this gameplay session\n",
    "* `commander_embodied` - False for all TEACh games\n",
    "* `initial_state`, `final_state` - Dictionaries consisting of the initial and final state of the world including\n",
    "    * `time_start` - \n",
    "    * `agents` - Position and orientation of each agent/ camera at start and end of episode\n",
    "    * `objects` - A list of the state of all objects at the start and end of the episode. Each object is represented by a dictionary whose keys are property names and values are property values.\n",
    "    * `custom_object_metadata` - A dictionary to track custom properties in our codebase that are not present in AI2-THOR. This is a dictionary with AI2-THOR objectId as key and a dictionary of (custom_property_name, custom_property_value) pairs as values\n",
    "* `interactions` - An ordered list of interactions that occurred in the environment, each represented by a dictionary of\n",
    "    * `agent_id` - The agent that took the action\n",
    "    * `action_id` - Which action was taken\n",
    "    * `time_start` - Duration of time between start of episode and when this action started\n",
    "    * `duration` - Duration of time (in sec) taken to execute this action\n",
    "    * `success` - 1 if the action was successfully executed during data collection and 0 otherwise. An example of a case where `success` might be 0 is if the human annotator tried to pick up an object from too far away \n",
    "    * Action specific keys. Some examples include\n",
    "        * `utterance` for a `Text` action - Stores the text value of the utterance made\n",
    "        * `pose_delta` and `pose` for a navigation action\n",
    "        \n",
    "Code snippet to print out the sequence of actions taken in an episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coated-hayes",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:09.267939Z",
     "start_time": "2023-11-22T12:30:09.261940Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_actions_from_game_dict(game_dict, definitions):\n",
    "    interactions = game_dict[\"tasks\"][0][\"episodes\"][0][\"interactions\"]\n",
    "    print(\n",
    "        \"Time Start\",\n",
    "        \"Action Success\".ljust(15, \" \"),\n",
    "        \"Agent\".ljust(15, \" \"),\n",
    "        \"Action\".ljust(20, \" \"),\n",
    "        \"Utterance text / Object ID / Object X, Y\",\n",
    "    )\n",
    "    for interaction in interactions:\n",
    "        output_str = \"\".rjust(2, \" \")\n",
    "        output_str += (\"%.2f\" % interaction[\"time_start\"]).ljust(15, \" \")\n",
    "        output_str += str(interaction[\"success\"]).ljust(10, \" \")\n",
    "        output_str += definitions.map_agents_id2info[interaction[\"agent_id\"]][\"agent_name\"].ljust(15, \" \")\n",
    "        output_str += definitions.map_actions_id2info[interaction[\"action_id\"]][\"action_name\"].ljust(20, \" \")\n",
    "        if \"utterance\" in interaction:\n",
    "            output_str += interaction[\"utterance\"]\n",
    "        elif \"oid\" in interaction and interaction[\"oid\"] is not None:\n",
    "            output_str += interaction[\"oid\"]\n",
    "        elif \"x\" in interaction and \"y\" in interaction:\n",
    "            output_str += \"(\" + str(interaction[\"x\"]) + \", \" + str(interaction[\"y\"]) + \")\"\n",
    "        print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "undefined-decline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:10.778812Z",
     "start_time": "2023-11-22T12:30:10.727244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Start Action Success  Agent           Action               Utterance text / Object ID / Object X, Y\n",
      "  15.29          0         Commander      OpenProgressCheck   \n",
      "  27.85          1         Commander      Text                I need the newspaper to be placed on a single table.\n",
      "  29.49          1         Commander      SelectOid           \n",
      "  39.11          1         Driver         Text                what should i do\n",
      "  61.21          1         Driver         Pan Left            \n",
      "  61.59          1         Driver         Pan Left            \n",
      "  61.84          1         Driver         Pan Left            \n",
      "  62.12          1         Commander      Text                I need the newspaper placed on a single table.\n",
      "  70.16          1         Driver         Pickup              Newspaper|-04.15|+00.36|-02.48\n",
      "  87.74          1         Driver         Place               CoffeeTable|-02.47|+00.00|-02.49\n",
      "  92.55          1         Commander      OpenProgressCheck   \n"
     ]
    }
   ],
   "source": [
    "print_actions_from_game_dict(game_dict, definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-springer",
   "metadata": {},
   "source": [
    "Note that for all object interactions, the relative coordinates of the object on the agent's egocentric image are available in `interaction['x'], interaction['y']`. In the cases where the wrapper was able to resolve these to an object ID using the segmentation frame, we also have the ID of the object interacted with in `interaction['oid']` but if the wrapper was forced to backoff to raycasting, then this is not available.   \n",
    "\n",
    "It is also possible to import a game file into a `Dataset` object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extraordinary-giant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:12.800055Z",
     "start_time": "2023-11-22T12:30:12.794107Z"
    }
   },
   "outputs": [],
   "source": [
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "game = Dataset.import_json(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-export",
   "metadata": {},
   "source": [
    "The following is how the code snippet to print out the same action info would look using the object oriented representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wanted-shooting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:18.540971Z",
     "start_time": "2023-11-22T12:30:18.533361Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_actions_from_game_as_dataset(game, definitions):\n",
    "    interactions = game.tasks[0].episodes[0].interactions\n",
    "    print(\n",
    "        \"Time Start\",\n",
    "        \"Action Success\".ljust(15, \" \"),\n",
    "        \"Agent\".ljust(15, \" \"),\n",
    "        \"Action\".ljust(20, \" \"),\n",
    "        \"Utterance text / Object ID / Object X, Y\",\n",
    "    )\n",
    "    for interaction in interactions:\n",
    "        output_str = \"\".rjust(2, \" \")\n",
    "        output_str += (\"%.2f\" % interaction.time_start).ljust(15, \" \")\n",
    "        output_str += str(interaction.status).ljust(10, \" \")\n",
    "        output_str += definitions.map_agents_id2info[interaction.agent_id][\"agent_name\"].ljust(15, \" \")\n",
    "        output_str += definitions.map_actions_id2info[interaction.action.action_id][\"action_name\"].ljust(20, \" \")\n",
    "        if isinstance(interaction.action, Action_Keyboard):\n",
    "            output_str += interaction.action.utterance\n",
    "        if isinstance(interaction.action, Action_ObjectInteraction):\n",
    "            if interaction.action.oid is None:\n",
    "                output_str += \"(\" + str(interaction.action.x) + \", \" + str(interaction.action.y) + \")\"\n",
    "            else:\n",
    "                output_str += interaction.action.oid\n",
    "        print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "experimental-warehouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:19.386377Z",
     "start_time": "2023-11-22T12:30:19.378665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Start Action Success  Agent           Action               Utterance text / Object ID / Object X, Y\n",
      "  15.29          None      Commander      OpenProgressCheck   \n",
      "  27.85          None      Commander      Text                I need the newspaper to be placed on a single table.\n",
      "  29.49          None      Commander      SelectOid           \n",
      "  39.11          None      Driver         Text                what should i do\n",
      "  61.21          None      Driver         Pan Left            \n",
      "  61.59          None      Driver         Pan Left            \n",
      "  61.84          None      Driver         Pan Left            \n",
      "  62.12          None      Commander      Text                I need the newspaper placed on a single table.\n",
      "  70.16          None      Driver         Pickup              Newspaper|-04.15|+00.36|-02.48\n",
      "  87.74          None      Driver         Place               CoffeeTable|-02.47|+00.00|-02.49\n",
      "  92.55          None      Commander      OpenProgressCheck   \n"
     ]
    }
   ],
   "source": [
    "print_actions_from_game_as_dataset(game, definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-instruction",
   "metadata": {},
   "source": [
    "Note that while the object oriented representation of the game can be manipulated more easily in the code, the task of the game does not get perfectly loaded. Specifically, when loading a game file, no attempt is made to resolve components of tasks that are themselves tasks. Additionally, the final state does not get loaded. The following code snippet shows how to check whether the task associated with a gameplay session is complete at the final state, by directly loading the game json file as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fabulous-aquarium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:20.557385Z",
     "start_time": "2023-11-22T12:30:20.514490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "definitions = Definitions(version=\"2.0\")\n",
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)\n",
    "game_task = game_dict[\"tasks\"][0]\n",
    "task_to_check = copy.deepcopy(\n",
    "    definitions.map_tasks_name2info[game_task[\"task_name\"]]\n",
    ")  # Copying is important if you're sharing a definitions object across calls\n",
    "task_to_check.task_params = game_task[\"task_params\"]\n",
    "final_state_objects = game_dict[\"tasks\"][0][\"episodes\"][0][\"final_state\"][\"objects\"]\n",
    "task_check_output = task_to_check.check_episode_progress(final_state_objects)\n",
    "print(task_check_output[\"success\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-excellence",
   "metadata": {},
   "source": [
    "The utterances in successful human-human sessions in the TEACh dataset are now annotated with dialog acts. This was done in two steps - first utterances were corrected to correct spelling mistakes, expand contractions and resolve some other issues. The corrected utterances were then annotated with dialog acts. An utterance can contain more than one dialog act. If it contains more than one dialog act, the utterance is divided into segments corresponding to each dialog act. The following code snippet prints the original utterance, the corrected utterance and each segment with the associated dialog act.  \n",
    "**Note: Currently the object oriented representation does not load dialog act anotations. If you wish to use the dialog act annotations please load the game json file directly into a dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aggressive-birth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:21.612678Z",
     "start_time": "2023-11-22T12:30:21.573462Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_utterances_and_dialog_acts(game_dict, definitions):\n",
    "    interactions = game_dict[\"tasks\"][0][\"episodes\"][0][\"interactions\"]\n",
    "    for interaction in interactions:\n",
    "        if \"utterance\" in interaction:\n",
    "            output_str = \"\"\n",
    "            output_str += definitions.map_agents_id2info[interaction[\"agent_id\"]][\"agent_name\"].ljust(15, \" \")\n",
    "            output_str += \"Utterance: \" + interaction[\"utterance\"] + \"\\n\"\n",
    "            output_str += \"\".ljust(15, \" \") + \"Corrected: \" + interaction[\"corrected_utterance\"] + \"\\n\"\n",
    "            output_str += \"\".ljust(15, \" \") + \"DAs with segments: \\n\"\n",
    "            for idx in range(len(interaction[\"da_metadata\"][\"das\"])):\n",
    "                # interaction[\"da_metadata\"][\"text_segments\"] and interaction[\"da_metadata\"][\"das\"] are lists of length 3\n",
    "                # If an utterance has fewer than 3 DAs then the extra segments and DAs are empty\n",
    "                # No utterance has more than 3 DAs\n",
    "                utt_segment = interaction[\"da_metadata\"][\"text_segments\"][idx]\n",
    "                da = interaction[\"da_metadata\"][\"das\"][idx]\n",
    "                if len(da) > 0:\n",
    "                    output_str += \"\".ljust(30, \" \") + da + \": \" + utt_segment + \"\\n\"\n",
    "            print(output_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "complicated-saturday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:22.420410Z",
     "start_time": "2023-11-22T12:30:22.313161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commander      Utterance: I need the newspaper to be placed on a single table.\n",
      "               Corrected: I need the newspaper to be placed on a single table.\n",
      "               DAs with segments: \n",
      "                              Instruction: I need the newspaper to be placed on a single table.\n",
      "\n",
      "\n",
      "Driver         Utterance: what should i do\n",
      "               Corrected: what should i do\n",
      "               DAs with segments: \n",
      "                              RequestForInstruction: what should i do\n",
      "\n",
      "\n",
      "Commander      Utterance: I need the newspaper placed on a single table.\n",
      "               Corrected: I need the newspaper placed on a single table.\n",
      "               DAs with segments: \n",
      "                              Instruction: I need the newspaper placed on a single table.\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)\n",
    "print_utterances_and_dialog_acts(game_dict, definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-dominant",
   "metadata": {},
   "source": [
    "### EDH Instances\n",
    "EDH instances are stored in `json` files. The `edh_instances` subdirectory consists of one subdirectory per split each containing EDH instances of that split. EDH instances do not have a corresponding object oriented representation and need to be manipulated as dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "quiet-discussion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T12:30:23.675740Z",
     "start_time": "2023-11-22T12:30:23.641458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dialog_history', 'driver_action_history', 'driver_image_history', 'driver_actions_future', 'driver_images_future', 'interactions', 'game_id', 'instance_id', 'pred_start_idx', 'init_state_diff', 'final_state_diff', 'state_changes', 'history_subgoals', 'future_subgoals', 'expected_init_goal_conditions_total', 'expected_init_goal_conditions_satisfied', 'dialog_history_cleaned', 'dialog_history_with_das'])\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(data_dir, \"edh_instances/train/7d2a79f43e605c36_1657.edh0.json\")\n",
    "with open(f) as h:\n",
    "    edh_instance = json.load(h)\n",
    "print(edh_instance.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The components of an EDH instance are:\n",
    "* `game_id` - ID of the gameplay session this was created from (the filename of a gameplay session file is of the form game_id.game.json)\n",
    "* `instance_id` - ID of this EDH instance\n",
    "* `interactions` - Subset of game interactions used to create this EDH instance (note that on the test set `interactions` will be modified so that actions to be predicted will not be included); Utterance interactions now have dialog act information in the same format as in the game\n",
    "* `pred_start_idx` - Start index of actions to be predicted in `interactions` \n",
    "* `dialog_history` - Utterances in dialog history of the EDH instance paired with the speaker for each turn\n",
    "* `dialog_history_cleaned` - Cleaned version of `dialog_history` with spell correction and removal of utterances commenting on the annotation interface (see Appendix B for details of data cleaning)\n",
    "* `driver_action_history` - Environment actions provided as history. Each action is represented as a dictionary containing\n",
    "    * `action_id`, `action_name` of the action according to the action definition\n",
    "    * `action_idx` - Modified `action_id` to be in the range 0-35 for easier use in prediction (note that this still contains unused actions)\n",
    "    * `time_start` - Timestamp from `interaction` corresponding to this action\n",
    "    * `obj_interaction_action` - 1 if the action is an object interaction action and 0 otherwise\n",
    "    * `oid` - Object ID of the object interacted with; None if the object is unknown or if the action was not an object interaction action\n",
    "    * `x`, `y` - Relative coordinates on egocentric image indicating the coordinate used for an object interaction action; None is the action was not an object interaction action\n",
    "* `driver_image_history` - Filename of image file of egocentric driver observation preceding each action in `driver_action_history`, that is, `driver_image_history[idx]` is the filename where the image for the driver's egocentric observation just before taking action `driver_action_history[idx]` is saved. \n",
    "* `driver_actions_future` - Environment actions to be predicted; Format is identical to `driver_action_history`; Not available at test time\n",
    "* `driver_images_future` - Image observations corresponding to environment actions to be predicted; Format is identical to `driver_image_history`; Not available at test time\n",
    "* `history_subgoals` - Programmatically created sequence of \"subgoals\" corresponding to environment actions provided as history - this is created by replacing every sequence of navigation actions with an abstract \"Navigate\" action with the destination as the next object manipulated. \n",
    "* `future_subgoals` - Programmatically created sequence of \"subgoals\" corresponding to environment actions to be predicted; Format identical to `history_subgoals`; Not available at test time\n",
    "* `expected_init_success` - Should be 1 for all EDH instances; This flag was used to filter EDH instances whose action history could not be reliably replayed\n",
    "* `expected_init_goal_conditions_total`, `expected_init_goal_conditions_satisfied` - When task completion status is checked, two of the statistics returned are `goal_conditions_total`, which is the number of object properties in the environment that were checked, and `goal_conditions_satisfied`, which is the number of checked object properties that were satisfied. These entries cache the values for these two statistics after replaying all history actions in the EDH instance. For calculating the goal condition success rate metric (GC), the task completion status is checked again after the model-predicted trajectory ends. At this time, along with the final task success rate, we also obtain final values, `final_goal_conditions_total` and `final_goal_conditions_satisfied`. GC is then calculated as `(1.0 - ((final_goal_conditions_total - final_goal_conditions_satisfied) / (expected_init_goal_conditions_total - expected_init_goal_conditions_satisfied)))`\n",
    "* `init_state_diff` - Differences in object properties between the initial state of the gameplay session and the state at the end of actions taken in the dialog history\n",
    "* `final_state_diff` - Differences in object properties between the initial state of the gameplay session and the state after playing all ground truth actions int he EDH instance\n",
    "* `state_changes` - State changes between `init_state_diff` and `final_state_diff` used to construct the task that will be used to evaluate this EDH instance\n",
    "\n",
    "For inference and evaluation it is recommended to use the provided inference script at [src/teach/cli/inference.py](https://github.com/alexa/teach/blob/main/src/teach/cli/inference.py)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19a69f4e365a60e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataset for vox fine-tuning\n",
    "## Trial play"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40dad6080bce572f"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def save_utterances_and_dialog_acts_to_csv(game_dict, definitions):\n",
    "    data_list = []\n",
    "    interactions = game_dict[\"tasks\"][0][\"episodes\"][0][\"interactions\"]\n",
    "    game_id = '' # ID of the gameplay session this was created from (the filename of a gameplay session file is of the form game_id.game.json)\n",
    "    instance_id = ''\n",
    "    episode_id = ''\n",
    "    for i, interaction in enumerate(interactions):\n",
    "        if \"utterance\" in interaction:\n",
    "            role = definitions.map_agents_id2info[interaction[\"agent_id\"]][\"agent_name\"]\n",
    "            utterance = interaction[\"utterance\"].strip()\n",
    "            da_utterance = \"\"\n",
    "            for idx in range(len(interaction[\"da_metadata\"][\"das\"])):\n",
    "                utt_segment = interaction[\"da_metadata\"][\"text_segments\"][idx]\n",
    "                da = interaction[\"da_metadata\"][\"das\"][idx]\n",
    "                if len(da) > 0:\n",
    "                    da_utterance += da + \": \" + utt_segment + \"|\"\n",
    "            # print(role, utterance, da_utterance)\n",
    "            data_list.append((game_id, instance_id, i, role, utterance, da_utterance))\n",
    "    return data_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:03:27.971535Z",
     "start_time": "2023-11-22T14:03:27.917961Z"
    }
   },
   "id": "1c53e0b0ea4d4468"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "definitions = Definitions(version=\"2.0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:01:04.466628Z",
     "start_time": "2023-11-22T14:01:04.451909Z"
    }
   },
   "id": "20ccd035677d5cb6"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "json_files = [os.path.join(data_dir, f\"games/train/{f}\") for f in os.listdir(os.path.join(data_dir, \"games/train\"))] # + [os.path.join(data_dir, f\"games/valid_seen/{f}\") for f in os.listdir(os.path.join(data_dir, \"games/valid_seen\"))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:01:05.070366Z",
     "start_time": "2023-11-22T14:01:05.051078Z"
    }
   },
   "id": "ab9e7de326c4df4a"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "1482"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:01:05.807127Z",
     "start_time": "2023-11-22T14:01:05.803534Z"
    }
   },
   "id": "71abd15d087f1e25"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_data_list = []\n",
    "\n",
    "for filename in json_files:\n",
    "    with open(filename) as h:\n",
    "        game_dict = json.load(h)\n",
    "        one_data_list = save_utterances_and_dialog_acts_to_csv(game_dict, definitions)\n",
    "        all_data_list.extend(one_data_list)\n",
    "\n",
    "df = pd.DataFrame(all_data_list, columns=['Role', 'Utterance', 'DA'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:11:16.977915Z",
     "start_time": "2023-11-22T14:10:48.657873Z"
    }
   },
   "id": "7c96f12264dfa1c9"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "            Role                                          Utterance  \\\n0      Commander  Good day!  We are preparing breakfast.  We fir...   \n1      Commander                The mug is located under the sink\\n   \n2      Commander                         Oh you found one!  Okay.\\n   \n3         Driver                                             done\\n   \n4      Commander  Great.  We are making a sandwich.  we need a k...   \n...          ...                                                ...   \n19322     Driver                           What shall I do today?\\n   \n19323  Commander               take the knife and slice the bread\\n   \n19324  Commander                                  toast the slice\\n   \n19325  Commander                    place the slices on the plate\\n   \n19326  Commander                       plate is inside the fridge\\n   \n\n                                                      DA  \n0      Greetings/Salutations: Good day!;Instruction: ...  \n1      InformationOnObjectDetails: The mug is located...  \n2                 Acknowledge: Oh you found one!  Okay.;  \n3                                     Acknowledge: done;  \n4      FeedbackPositive: Great.;Instruction: We are m...  \n...                                                  ...  \n19322     RequestForInstruction: What shall I do today?;  \n19323   Instruction: take the knife and slice the bread;  \n19324                      Instruction: toast the slice;  \n19325        Instruction: place the slices on the plate;  \n19326  InformationOnObjectDetails: plate is inside th...  \n\n[19327 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Role</th>\n      <th>Utterance</th>\n      <th>DA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Commander</td>\n      <td>Good day!  We are preparing breakfast.  We fir...</td>\n      <td>Greetings/Salutations: Good day!;Instruction: ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Commander</td>\n      <td>The mug is located under the sink\\n</td>\n      <td>InformationOnObjectDetails: The mug is located...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Commander</td>\n      <td>Oh you found one!  Okay.\\n</td>\n      <td>Acknowledge: Oh you found one!  Okay.;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Driver</td>\n      <td>done\\n</td>\n      <td>Acknowledge: done;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Commander</td>\n      <td>Great.  We are making a sandwich.  we need a k...</td>\n      <td>FeedbackPositive: Great.;Instruction: We are m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19322</th>\n      <td>Driver</td>\n      <td>What shall I do today?\\n</td>\n      <td>RequestForInstruction: What shall I do today?;</td>\n    </tr>\n    <tr>\n      <th>19323</th>\n      <td>Commander</td>\n      <td>take the knife and slice the bread\\n</td>\n      <td>Instruction: take the knife and slice the bread;</td>\n    </tr>\n    <tr>\n      <th>19324</th>\n      <td>Commander</td>\n      <td>toast the slice\\n</td>\n      <td>Instruction: toast the slice;</td>\n    </tr>\n    <tr>\n      <th>19325</th>\n      <td>Commander</td>\n      <td>place the slices on the plate\\n</td>\n      <td>Instruction: place the slices on the plate;</td>\n    </tr>\n    <tr>\n      <th>19326</th>\n      <td>Commander</td>\n      <td>plate is inside the fridge\\n</td>\n      <td>InformationOnObjectDetails: plate is inside th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>19327 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:11:16.991356Z",
     "start_time": "2023-11-22T14:11:16.985946Z"
    }
   },
   "id": "7882d126006b2772"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "f = os.path.join(data_dir, \"edh_instances/train/c29e584989d391ac_b7d5.edh2.json\")\n",
    "with open(f) as h:\n",
    "    edh_instance = json.load(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:46:38.253722Z",
     "start_time": "2023-11-22T14:46:38.217901Z"
    }
   },
   "id": "7efa70d015045c18"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['dialog_history', 'driver_action_history', 'driver_image_history', 'driver_actions_future', 'driver_images_future', 'interactions', 'game_id', 'instance_id', 'pred_start_idx', 'init_state_diff', 'final_state_diff', 'state_changes', 'history_subgoals', 'future_subgoals', 'expected_init_goal_conditions_total', 'expected_init_goal_conditions_satisfied', 'dialog_history_cleaned', 'dialog_history_with_das'])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edh_instance.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T14:47:18.827726Z",
     "start_time": "2023-11-22T14:47:18.815432Z"
    }
   },
   "id": "c1af6754ea6f2556"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "['Driver: hi',\n 'Driver: what should I do?',\n 'Commander: today we need to make a salad',\n 'Commander: please cut the lettuce using a knife',\n \"Driver: what's next?\",\n 'Commander: please cut the potato using the knife',\n 'Driver: did that',\n 'Commander: you need to cook the potato slice']"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[': '.join(utter) for utter in edh_instance['dialog_history_cleaned']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:04:50.371017Z",
     "start_time": "2023-11-22T15:04:50.356045Z"
    }
   },
   "id": "8422328660ba7ef6"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "('c29e584989d391ac_b7d5', 'c29e584989d391ac_b7d5.edh2')"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edh_instance['game_id'], edh_instance['instance_id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:01:53.102001Z",
     "start_time": "2023-11-22T15:01:53.094699Z"
    }
   },
   "id": "e656c580c25d33d4"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: hi. what should I do?\n",
      "Commander: today we need to make a salad. please cut the lettuce using a knife\n",
      "Driver: what's next?\n",
      "Commander: please cut the potato using the knife\n",
      "Driver: did that\n",
      "Commander: you need to cook the potato slice\n"
     ]
    }
   ],
   "source": [
    "def generate_role_utterance_pairs(utterances):\n",
    "    role_utterance_pairs = []\n",
    "    current_role = None\n",
    "    current_utterance = ''\n",
    "\n",
    "    for utterance in utterances:\n",
    "        role, text = utterance.split(': ', 1)\n",
    "\n",
    "        if role == current_role:\n",
    "            # If the current role is the same as the previous one, combine the utterances\n",
    "            current_utterance += '. ' + text\n",
    "        else:\n",
    "            # If the role changes, add the previous combined utterance to the list\n",
    "            if current_role is not None:\n",
    "                role_utterance_pairs.append((current_role, current_utterance.strip()))\n",
    "\n",
    "            # Start a new combined utterance for the new role\n",
    "            current_role = role\n",
    "            current_utterance = text\n",
    "\n",
    "    # Add the last combined utterance to the list\n",
    "    role_utterance_pairs.append((current_role, current_utterance.strip()))\n",
    "\n",
    "    return role_utterance_pairs\n",
    "\n",
    "# Input utterances\n",
    "utterances = ['Driver: hi',\n",
    "              'Driver: what should I do?',\n",
    "              'Commander: today we need to make a salad',\n",
    "              'Commander: please cut the lettuce using a knife',\n",
    "              \"Driver: what's next?\",\n",
    "              'Commander: please cut the potato using the knife',\n",
    "              'Driver: did that',\n",
    "              'Commander: you need to cook the potato slice']\n",
    "\n",
    "# Generate question-answer pairs\n",
    "role_utterance_pairs = generate_role_utterance_pairs(utterances)\n",
    "\n",
    "# Print the result\n",
    "for role, utterance in role_utterance_pairs:\n",
    "    print(f'{role}: {utterance}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:16:36.329777Z",
     "start_time": "2023-11-22T15:16:36.317372Z"
    }
   },
   "id": "f1970c52e8407ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue History: hi. what should I do?\n",
      "Current Utterance: today we need to make a salad. please cut the lettuce using a knife\n",
      "\n",
      "Dialogue History: today we need to make a salad. please cut the lettuce using a knife\n",
      "Current Utterance: what's next?\n",
      "\n",
      "Dialogue History: what's next?\n",
      "Current Utterance: please cut the potato using the knife\n",
      "\n",
      "Dialogue History: please cut the potato using the knife\n",
      "Current Utterance: did that\n",
      "\n",
      "Dialogue History: did that\n",
      "Current Utterance: you need to cook the potato slice\n",
      "\n",
      "Dialogue History: you need to cook the potato slice\n",
      "Current Utterance: \n"
     ]
    }
   ],
   "source": [
    "def generate_one_turn_dialogue_history_pairs(role_conversation_pairs):\n",
    "    dialogue_pairs = []\n",
    "\n",
    "    current_role = None\n",
    "    dialogue_history = []\n",
    "\n",
    "    for role, text in role_conversation_pairs:\n",
    "        # role, text = utterance.split(': ', 1)\n",
    "\n",
    "        if role == current_role:\n",
    "            # If the current role is the same as the previous one, add to the dialogue history\n",
    "            dialogue_history.append(text)\n",
    "        else:\n",
    "            # If the role changes, create a dialogue history-current utterance pair\n",
    "            if current_role is not None:\n",
    "                dialogue_pairs.append((' '.join(dialogue_history), text))\n",
    "\n",
    "            # Update current role and reset dialogue history\n",
    "            current_role = role\n",
    "            dialogue_history = [text]\n",
    "\n",
    "    # Add the last dialogue history-current utterance pair to the list\n",
    "    dialogue_pairs.append((' '.join(dialogue_history), ''))\n",
    "\n",
    "    return dialogue_pairs\n",
    "\n",
    "# Generate dialogue history-current utterance pairs\n",
    "dialogue_pairs = generate_one_turn_dialogue_history_pairs(role_utterance_pairs)\n",
    "\n",
    "# Print the result\n",
    "for dialogue_history, current_utterance in dialogue_pairs:\n",
    "    print(f'Dialogue History: {dialogue_history}')\n",
    "    print(f'Current Utterance: {current_utterance}\\n')\n",
    "    # print({'input': dialogue_history, 'output': current_utterance})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:24:20.893336Z",
     "start_time": "2023-11-22T15:24:20.872027Z"
    }
   },
   "id": "6a97e9ea1234ad48"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def generate_all_turn_dialogue_history_pairs(role_conversation_pairs):\n",
    "    dialogue_pairs = []\n",
    "\n",
    "    dialogue_history = []\n",
    "\n",
    "    for role, text in role_conversation_pairs:\n",
    "        # Add the current utterance to the dialogue history\n",
    "        dialogue_history.append(text)\n",
    "\n",
    "        # Create a dialogue history-current utterance pair\n",
    "        dialogue_pairs.append((' '.join(dialogue_history[:-1]), dialogue_history[-1]))\n",
    "\n",
    "    return dialogue_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:26:34.745699Z",
     "start_time": "2023-11-22T15:26:34.722679Z"
    }
   },
   "id": "bf904ce08883b21d"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# Generate dialogue history-current utterance pairs\n",
    "full_dialogue_pairs = generate_all_turn_dialogue_history_pairs(role_utterance_pairs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:26:35.303722Z",
     "start_time": "2023-11-22T15:26:35.296888Z"
    }
   },
   "id": "74c1b0d2e726a883"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue History: \n",
      "Current Utterance: hi. what should I do?\n",
      "\n",
      "Dialogue History: hi. what should I do?\n",
      "Current Utterance: today we need to make a salad. please cut the lettuce using a knife\n",
      "\n",
      "Dialogue History: hi. what should I do? today we need to make a salad. please cut the lettuce using a knife\n",
      "Current Utterance: what's next?\n",
      "\n",
      "Dialogue History: hi. what should I do? today we need to make a salad. please cut the lettuce using a knife what's next?\n",
      "Current Utterance: please cut the potato using the knife\n",
      "\n",
      "Dialogue History: hi. what should I do? today we need to make a salad. please cut the lettuce using a knife what's next? please cut the potato using the knife\n",
      "Current Utterance: did that\n",
      "\n",
      "Dialogue History: hi. what should I do? today we need to make a salad. please cut the lettuce using a knife what's next? please cut the potato using the knife did that\n",
      "Current Utterance: you need to cook the potato slice\n"
     ]
    }
   ],
   "source": [
    "for dialogue_history, current_utterance in full_dialogue_pairs:\n",
    "    print(f'Dialogue History: {dialogue_history}')\n",
    "    print(f'Current Utterance: {current_utterance}\\n')\n",
    "    # print({'input': dialogue_history, 'output': current_utterance})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:26:35.755099Z",
     "start_time": "2023-11-22T15:26:35.753158Z"
    }
   },
   "id": "dc5138cfb001bbda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start prepare!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eabb639cb36f2a6"
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "data_dir = \"/media/PampusData/jpei/teach-dataset/edh_instances\"\n",
    "json_files_train = [os.path.join(data_dir, f\"train/{f}\") for f in os.listdir(os.path.join(data_dir, \"train\"))] \n",
    "json_files_valid = [os.path.join(data_dir, f\"valid_seen/{f}\") for f in os.listdir(os.path.join(data_dir, \"valid_seen\"))] \n",
    "json_files_test = [os.path.join(data_dir, f\"valid_unseen/{f}\") for f in os.listdir(os.path.join(data_dir, \"valid_unseen\"))] "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:37:34.029183Z",
     "start_time": "2023-11-22T17:37:33.849191Z"
    }
   },
   "id": "59be2e66af8e516a"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "(5475, 608, 2149)"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files_train), len(json_files_valid), len(json_files_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:36:22.327237Z",
     "start_time": "2023-11-22T15:36:22.311397Z"
    }
   },
   "id": "18ad40b215a0f53b"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "'/media/PampusData/jpei/teach-dataset/edh_instances/train/0008f3c95e006303_2053.edh0.json'"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:36:58.941382Z",
     "start_time": "2023-11-22T15:36:58.907995Z"
    }
   },
   "id": "efe56948aa56162c"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Commander', 'Good day! We are preparing breakfast. We first need to wash a dirty mug.']]\n"
     ]
    }
   ],
   "source": [
    "with open(json_files_train[0], 'r') as h:\n",
    "    edh_instance = json.load(h)\n",
    "    print(edh_instance['dialog_history_cleaned'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T15:39:49.129735Z",
     "start_time": "2023-11-22T15:39:49.075411Z"
    }
   },
   "id": "d82b7ed8704a3198"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4715342c43fbbf"
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "def generate_finetune_QA_pairs(json_files, data_dir=data_dir, data_name='teach_edh_train.jsonl'):\n",
    "    data_list = []\n",
    "    count_pairs = 0\n",
    "    for f in tqdm(json_files):\n",
    "        with open(f) as h:\n",
    "            edh = json.load(h)\n",
    "            # print(edh['dialog_history_cleaned'])\n",
    "            utterances = [': '.join(utter) for utter in edh['dialog_history_cleaned']]\n",
    "            role_utterance_pairs = generate_role_utterance_pairs(utterances)\n",
    "            full_dialogue_pairs = generate_all_turn_dialogue_history_pairs(role_utterance_pairs)\n",
    "            for dialogue_history, current_utterance in full_dialogue_pairs:\n",
    "                # print(f'Dialogue History: {dialogue_history}')\n",
    "                # print(f'Current Utterance: {current_utterance}\\n')\n",
    "                if dialogue_history!='' and current_utterance!='':\n",
    "                    count_pairs +=1\n",
    "                    line = (dialogue_history, current_utterance)\n",
    "                    # line = {\"input\": f\"{dialogue_history}\", \"output\": f\"{current_utterance}\"}\n",
    "                    # line = '{\"input\": \"%s\", \"output\": \"%s\"}\\n' % (dialogue_history, current_utterance)\n",
    "                    data_list.append(line)\n",
    "                    # print({\"input\": dialogue_history, \"output\": current_utterance})\n",
    "    \n",
    "    data_list = [{\"input\": f\"{dialogue_history}\", \"output\": f\"{current_utterance}\"} for dialogue_history, current_utterance in list(set(data_list))] # Only remain the unique pairs\n",
    "    with open(f'{data_dir}/{data_name}', 'w') as fw:\n",
    "        json.dump(data_list, fw)\n",
    "        \n",
    "    print(f'Dataset {data_name} contains QA pairs: {len(data_list)} unique /{count_pairs} total')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:38:54.947141Z",
     "start_time": "2023-11-22T17:38:54.925681Z"
    }
   },
   "id": "a51fd706032b0b1d"
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/608 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0017fd544974389a84deebb0a03cb59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset teach_edh_valid.jsonl contains QA pairs: 1124 unique /3491 total\n"
     ]
    }
   ],
   "source": [
    "generate_finetune_QA_pairs(json_files_valid, data_dir=data_dir, data_name='teach_edh_valid.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:38:58.309710Z",
     "start_time": "2023-11-22T17:38:55.908337Z"
    }
   },
   "id": "75d363432b96ae0d"
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5475 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10bf8652e54b4504bf18f2af8e3e2c71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset teach_edh_train.jsonl contains QA pairs: 9634 unique /29965 total\n"
     ]
    }
   ],
   "source": [
    "generate_finetune_QA_pairs(json_files_train, data_dir=data_dir, data_name='teach_edh_train.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:39:22.371843Z",
     "start_time": "2023-11-22T17:39:00.358346Z"
    }
   },
   "id": "ccdbdd7e154bdb95"
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2149 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e203e4527f642d3951e9f0ff8a3eac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset teach_edh_test.jsonl contains QA pairs: 3831 unique /10774 total\n"
     ]
    }
   ],
   "source": [
    "generate_finetune_QA_pairs(json_files_test, data_dir=data_dir, data_name='teach_edh_test.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:39:34.394048Z",
     "start_time": "2023-11-22T17:39:24.748721Z"
    }
   },
   "id": "6b1a4f4d95d435cf"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teach_edh_test.jsonl   teach_edh_valid.jsonl  valid_seen\r\n",
      "teach_edh_train.jsonl  train\t\t      valid_unseen\r\n"
     ]
    }
   ],
   "source": [
    "! ls \"/media/PampusData/jpei/teach-dataset/edh_instances\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:04:10.129461Z",
     "start_time": "2023-11-22T16:04:10.007787Z"
    }
   },
   "id": "32915f6ea249efc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7619d821d3c11998"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
