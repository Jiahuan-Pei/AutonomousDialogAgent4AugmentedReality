{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Setup openai agent and test it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64604659c267c7e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.chat import MessagesPlaceholder\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from callbacks import AgentCallbackHandler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T01:48:08.832210Z",
     "start_time": "2023-12-20T01:48:08.831036Z"
    }
   },
   "id": "90d4cb781059bd31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_instruction = f\"\"\"\n",
    "The task it to generate conversations between trainer and trainee grounded on the task-specific guidelines.\n",
    "The trainer aims to teach the trainee how to accomplish the assembly task based on the task-specific guidelines, supported by an XR application.\n",
    "Specifically, the trainee is wearing AR glasses to see both VR environment and real world.\n",
    "The trainee knows nothing about the guidelines before trainer's guidance.\n",
    "For each step,\n",
    "the trainee must ask at least one deep-dive question, or request a troublesome issue if he or she cannot follow the guide, or call tools from XR application and learn how to use those tools;\n",
    "the trainer must answer the question, assist the trainee, show them the responses of the execution of the tools.\n",
    "At the end of a conversation,\n",
    "first, trainer must ask if the trainee has accomplished the task and the trainee must tell if the trainee can accomplish the task;\n",
    "second, trainer must ask how is user experience, and the trainee provide feedback on the user experience.\n",
    "You must add a section title to separate which key point in the guideline in the generated conversation and generate until the final step of the guidelines.\n",
    "\"\"\"\n",
    "\n",
    "tool_descriptions = {\n",
    "    \"StartAssemble\": \"Useful Unity tool to initiate the assembly process.\",\n",
    "    \"NextStep\": \"Useful Unity tool to move to the next assembly step.\",\n",
    "    \"FrontStep\": \"Useful Unity tool to go back to the previous assembly step.\",\n",
    "    \"Explode\": \"Useful Unity tool to trigger an explosion for detailed viewing.\",\n",
    "    \"Recover\": \"Useful Unity tool to restore the initial state of AR objects after explosion.\",\n",
    "    \"FinishedVideo\": \"Useful Unity tool to end the assembly process and show a video of the assembled LEGO bricks.\",\n",
    "    \"ReShow\": \"Useful Unity tool to repeat the current assembly step.\",\n",
    "    \"Enlarge\": \"Useful Unity tool to enlarge or zoom out the current object.\",\n",
    "    \"Shrink\": \"Useful Unity tool to shrink or zoom in the current object.\",\n",
    "    \"GoToStep\": \"Useful Unity tool to go to the given an assembly step number.\",\n",
    "    \"Rotate\": \"Useful Unity tool to rotate the current object to a direction.\",\n",
    "    \"ShowPieces\": \"Useful Unity tool to show all candidate LEGO pieces to be assembled.\",\n",
    "    \"HighlightCorrectComponents\": \"Useful Unity tool to highlight correct attachment points and components.\",\n",
    "    \"GetCurrentStep\": \"Useful Unity tool to get the number of the current step.\",\n",
    "    \"GetRemainingStep\": \"Useful Unity tool to get the number of the remaining steps.\",\n",
    "    \"CheckStepStatusVR\": \"Useful Unity tool to check if the current step in Unity is accomplished correctly or not. If the current assembly sequence recorded in Unity is the same as the manual assembly sequence, then it is correct, otherwise, it is incorrect.\",\n",
    "    \"APICallObjectRecognitionAR\": \"Useful AR tool to call the VLM agent to identify LEGO pieces based on the provided video streaming data from AR glasses and highlights the recognized pieces in the AR environment.\",\n",
    "    \"APICallCheckStepStatusAR\": \"Useful AR tool to call the VLM agent to determine if the current assembly step is completed correctly or not, using the provided video streaming data from AR glasses as input.\"\n",
    "}\n",
    "\n",
    "sys_prompt = f\"\"\"\n",
    "### Instruction:\n",
    "{task_instruction}\n",
    "\n",
    "You can call the following tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "### Examples:\n",
    "Example 1:\n",
    "Trainee: Hi, I'm ready to start building the LEGO Creator set \"Creator Sunken Treasure Mission\". What should I do first?\n",
    "Trainer: Great! Let's start by opening the box. It might be a bit tricky, so you can ask someone to help you with that.\n",
    "\n",
    "Example 2:\n",
    "Trainee: I've added the bricks on top of the angle plates. What's the next step?\n",
    "Trainer: That completes this step! You've successfully built the stabilizer bars and added the angle plates and bricks. Is there anything you're unsure about or any questions you have?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T01:48:08.833592Z",
     "start_time": "2023-12-20T01:48:08.833128Z"
    }
   },
   "id": "78702cf2c3970382"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='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'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T01:48:08.833282Z"
    }
   },
   "id": "61ee6ba0e8af6e81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Contains the configuration of the LLM.\n",
    "    \"\"\"\n",
    "    model = 'gpt-3.5-turbo-16k-0613'\n",
    "    try:\n",
    "        OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "    except:\n",
    "        print(f'OPENAI_API_KEY={OPENAI_API_KEY}')\n",
    "    temperature = 0.0\n",
    "    verbose = True\n",
    "    \n",
    "    \n",
    "class LegoAPIWrapper:\n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "\n",
    "        # Dynamically create methods based on the function names\n",
    "        for function_name in tools:\n",
    "            setattr(self, function_name, self._create_class_method(function_name))\n",
    "\n",
    "    def __getattr__(self, function_name):\n",
    "        if function_name in self.tools:\n",
    "            return self._create_class_method(function_name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{function_name}'\")\n",
    "\n",
    "    def _create_class_method(self, function_name):\n",
    "        def method():\n",
    "            print(f\"Unity: Method '{function_name}' has been called.\")\n",
    "            return f\"Response of '{function_name}'\"\n",
    "\n",
    "        return method\n",
    "    \n",
    "\n",
    "def setup_memory() -> Tuple[Dict, ConversationBufferMemory]:\n",
    "    \"\"\"\n",
    "    Sets up memory for the open ai functions agent.\n",
    "    :return a tuple with the agent keyword pairs and the conversation memory.\n",
    "    \"\"\"\n",
    "    system_message = SystemMessage(content=f\"{sys_prompt}\")\n",
    "    agent_kwargs = {\n",
    "        \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "        \"system_message\": system_message,\n",
    "    }\n",
    "    memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)\n",
    "\n",
    "    return agent_kwargs, memory\n",
    "\n",
    "# In the setup_tools function, access descriptions from LegoAPIWrapper\n",
    "def setup_tools() -> List[StructuredTool]:\n",
    "\n",
    "    lego_toolkits = LegoAPIWrapper(tool_descriptions)     # async toolkits\n",
    "\n",
    "    # Create StructuredTool objects with descriptions from LegoAPIWrapper\n",
    "    structured_tools = []\n",
    "    # structured_tools = [metadata_retriever]\n",
    "\n",
    "    for name, description in tool_descriptions.items():\n",
    "        func = getattr(lego_toolkits, name)\n",
    "        structured_tools.append(StructuredTool.from_function(func=func, name=name, description=description))\n",
    "\n",
    "    return structured_tools\n",
    "\n",
    "def setup_agent() -> AgentExecutor:\n",
    "    \"\"\"\n",
    "    Sets up the tools for a function based chain.\n",
    "    \"\"\"\n",
    "    cfg = Config()\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=cfg.temperature,\n",
    "        model=cfg.model,\n",
    "        verbose=cfg.verbose\n",
    "    )\n",
    "\n",
    "    agent_kwargs, memory = setup_memory()\n",
    "\n",
    "    tools = setup_tools()\n",
    "\n",
    "    return initialize_agent(\n",
    "        tools, \n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_FUNCTIONS, \n",
    "        verbose=False, \n",
    "        agent_kwargs=agent_kwargs,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "agent_executor: AgentExecutor = setup_agent()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T01:48:08.833377Z"
    }
   },
   "id": "851762635a819947"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_dir = '/media/Blue2TB3/jpei/vox_arta_dataset/manuals/lego'\n",
    "import json\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "count_dialogue = 0\n",
    "chunk_size = 10\n",
    "max_words = int(16385*0.75) \n",
    "\n",
    "def generate_conversation_per_file(fname, mdir=manual_dir):\n",
    "    with open(f'{mdir}/{fname}/{fname}.json', 'r', encoding='utf-8') as fr:\n",
    "        json_instructions = json.load(fr)['instructions']\n",
    "        summary = json_instructions[0]['text']\n",
    "        instructions = [d['text'] for d in json_instructions[1:]]\n",
    "        \n",
    "        ## Chunk the original instructions\n",
    "        n = math.ceil(len(instructions)/chunk_size)\n",
    "        for i_chunk in range(n):\n",
    "            output_file = f'{mdir}/{fname}/{fname}_{i_chunk}.txt'\n",
    "            if os.path.exists(output_file) and os.path.getsize(output_file)>0:\n",
    "                print('='*10, f'> Pass as already exist: {output_file}')\n",
    "            else:\n",
    "                start_index = i_chunk*chunk_size\n",
    "                end_index = min(i_chunk*chunk_size+chunk_size, len(instructions)-1)            \n",
    "                chuck_instruction_str = '\\n'.join(instructions[start_index:end_index]) \n",
    "                chuck_instruction_str = ' '.join(chuck_instruction_str.split()[:max_words])\n",
    "                print('*'*50, fname, f'; Chunk {i_chunk}/{n}', f'; Instruction indexes {start_index+1}: {end_index}', '*'*50)\n",
    "                # print(chuck_instruction_str)\n",
    "                \n",
    "                ## Prepare query prompt\n",
    "                query_prompt = f\"\"\"\n",
    "                    The task it to generate conversations between trainer and trainee grounded on the task-specific guidelines.\n",
    "                    ### Guidelines:\n",
    "                    {summary}\n",
    "                    {chuck_instruction_str}\n",
    "                    ### Response:\n",
    "                \"\"\".strip()\n",
    "                query_prompt = re.sub(r'\\s+', ' ', query_prompt)\n",
    "                query_prompt = re.sub(r'\\n+', '\\n', query_prompt)\n",
    "                # print('-'*50, '\\n', query_prompt)\n",
    "                print('$'*50, len(query_prompt.split()))\n",
    "                \n",
    "                ## Carefully call ChatGPT API as it costs credits!\n",
    "\n",
    "                response = agent_executor.run(query_prompt, callbacks=[AgentCallbackHandler()])\n",
    "                print(response)\n",
    "                with open(output_file, 'w') as fw:\n",
    "                    fw.write(response)\n",
    "                time.sleep(60*4) # Limit is 60000 tokens per minute\n",
    "    \n",
    "for folder_name in tqdm(os.listdir(manual_dir)):\n",
    "    if Path(os.path.join(manual_dir,folder_name)).is_dir():\n",
    "        generate_conversation_per_file(folder_name)\n",
    "    else:\n",
    "        print(f'Pass as not a folder {folder_name}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T01:48:08.833526Z"
    }
   },
   "id": "31cfaee030e8c779"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from callbacks import AgentCallbackHandler\n",
    "# agent_executor.run('Can you check if the current assembly step is completed correctly using the current AR data?', callbacks=[AgentCallbackHandler()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T01:48:08.833992Z",
     "start_time": "2023-12-20T01:48:08.833653Z"
    }
   },
   "id": "3cc11dc57229320a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Dataset generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c64a66d96d6cfa6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_conversations(input_folder, output_path):\n",
    "    data = []\n",
    "\n",
    "    # Recursively traverse the directory\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                input_path = os.path.join(root, filename)\n",
    "\n",
    "                # Read the content from the file\n",
    "                with open(input_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "\n",
    "                # Perform preprocessing (customize as needed)\n",
    "                preprocessed_content = preprocess_text(content)\n",
    "\n",
    "                # Extract trainee-trainer conversation pairs\n",
    "                conversation_pairs = extract_conversation_pairs(preprocessed_content)\n",
    "\n",
    "                # Append to the dataset\n",
    "                data.extend(conversation_pairs)\n",
    "\n",
    "    # Save the dataset to a JSONL file\n",
    "    with open(output_path, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for example in data:\n",
    "            jsonl_file.write(json.dumps(example, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # Compute and print dataset statistics\n",
    "    compute_dataset_statistics(data)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Add your specific text preprocessing steps here\n",
    "    # For example, removing special characters, extracting conversations, etc.\n",
    "    # Modify this function based on the structure of your dataset\n",
    "\n",
    "    # Example: Remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\n\\s]', '', text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def extract_conversation_pairs(text):\n",
    "    # Add your logic to extract trainee-trainer conversation pairs\n",
    "    # Modify this function based on the structure of your dataset\n",
    "    pairs = []\n",
    "\n",
    "    # Example: Split the text into lines and create pairs of consecutive lines\n",
    "    lines = text.split('\\n')\n",
    "    for i in range(0, len(lines)-1, 2):\n",
    "        trainee_input = lines[i].strip()\n",
    "        trainer_output = lines[i+1].strip()\n",
    "\n",
    "        # Create a pair with \"input\" and \"output\" keys\n",
    "        pair = {\"input\": trainee_input, \"output\": trainer_output}\n",
    "        pairs.append(pair)\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def compute_dataset_statistics(dataset):\n",
    "    num_examples = len(dataset)\n",
    "    avg_input_length = sum(len(example[\"input\"]) for example in dataset) / num_examples\n",
    "    avg_output_length = sum(len(example[\"output\"]) for example in dataset) / num_examples\n",
    "\n",
    "    print(\"Dataset Statistics:\")\n",
    "    print(f\"Number of Examples: {num_examples}\")\n",
    "    print(f\"Average Input Length: {avg_input_length:.2f} characters\")\n",
    "    print(f\"Average Output Length: {avg_output_length:.2f} characters\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder_path = '/media/Blue2TB3/jpei/vox_arta_dataset/manuals/lego'  # Replace with the actual path to your input folder\n",
    "    output_jsonl_path = '/media/Blue2TB3/jpei/vox_arta_dataset/manuals/lego/to/output_dataset.jsonl'  # Replace with the desired path for the output JSONL file\n",
    "\n",
    "    preprocess_conversations(input_folder_path, output_jsonl_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb03b814c56fa27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
